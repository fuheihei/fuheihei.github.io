[{"title":"并发编程 - 解析 ThreadPoolExecutor","url":"http://fuheihei.github.io/java-concurrency-programming/thread-executor/","content":"解析ThreadPoolExecutor本文通过源码解析 ThreadPoolExecutor，来了解实践中如何设置线程池参数，分析美团线程池实践中如何动态设置线程池参数。\nThreadPoolExecutor 常用的方法Executor\nvoid execute(Runnable command)\n\n\nExecutorService\nvoid shutdown();\nList&lt;Runnable> shutdownNow();\nboolean isShutdown();\nboolean isTerminated();\nboolean awaitTermination(long timeout, TimeUnit unit);\nFuture&lt;T> submit();\nList&lt;Future&lt;T>> invokeAll();\nT invokeAny();\n\n\nThreadPoolExecutor\ngetPoolSize #线程池的线程数\ngetActiveCount # 活跃线程数\ngetCompletedTaskCount #完成的任务数\ngetQueue().size()  #队列中的任务数\n\n\n\n\nThreadPoolExecutor 构造函数Executors的固定线程池，缓存线程池，单线程池也是通过构造ThreadPoolExecutor对象的方式构造出来的。\n/**\n     * 用给定的初始参数创建一个新的ThreadPoolExecutor。\n     */\n    public ThreadPoolExecutor(int corePoolSize, //线程池的核心线程数量\n                              int maximumPoolSize,//线程池的最大线程数\n                              long keepAliveTime,\n                              //当线程数大于核心线程数时，多余的空闲线程存活的最长时间\n                              TimeUnit unit,//时间单位\n                              BlockingQueue&lt;Runnable> workQueue,\n                              //任务队列，用来储存等待执行任务的队列\n                              ThreadFactory threadFactory,//线程工厂，用来创建线程，一般默认即可\n                              RejectedExecutionHandler handler\n                              //拒绝策略，当提交的任务过多而不能及时处理时，我们可以定制策略来处理任务\n                               ) &#123;\n        if (corePoolSize &lt; 0 ||\n            maximumPoolSize &lt;= 0 ||\n            maximumPoolSize &lt; corePoolSize ||\n            keepAliveTime &lt; 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    &#125;\n\n\n\n使用阿里巴巴推荐的创建线程池的方式\nprivate static final int CORE_POOL_SIZE = 5;\nprivate static final int MAX_POOL_SIZE = 10;\nprivate static final int QUEUE_CAPACITY = 100;\nprivate static final Long KEEP_ALIVE_TIME = 1L;    \n\n//通过ThreadPoolExecutor构造函数自定义参数创建\nThreadPoolExecutor executor = new ThreadPoolExecutor(\n  CORE_POOL_SIZE,\n  MAX_POOL_SIZE,\n  KEEP_ALIVE_TIME,\n  TimeUnit.SECONDS,\n  new ArrayBlockingQueue&lt;>(QUEUE_CAPACITY),\n  new ThreadPoolExecutor.CallerRunsPolicy());\n\n\n\n\nThreadPoolExecutor 3 个最重要的参数：\n\ncorePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。\nmaximumPoolSize :  最大池数量，注意：实际最大值在内部由 CAPACITY 限制\nworkQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。\n\nThreadPoolExecutor其他常见参数:\n\nkeepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；\nunit : keepAliveTime 参数的时间单位。\nthreadFactory :executor 创建新线程的时候会用到。\nhandler :饱和策略。关于饱和策略下面单独介绍一下。\n\nThreadPoolExecutor 饱和策略定义:\n如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，ThreadPoolTaskExecutor 定义一些策略:\n\nThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。默认是该策略\nThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。对于可伸缩的应用程序，如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。\nThreadPoolExecutor.DiscardPolicy：不处理新任务，直接丢弃掉。\nThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。\n\n设置线程池名称为了便于定位问题，线程池在实践中应当命名。\n\n利用 ThreadFactoryBuilder\n\n\t\nThreadFactory threadFactory = new ThreadFactoryBuilder()\n                        .setNameFormat(threadNamePrefix + \"-%d\")\n                        .setDaemon(true).build();\nExecutorService threadPool = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, TimeUnit.MINUTES, workQueue, threadFactory)\n\n\n\n\n自己实现 ThreadFactory\n\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.ThreadFactory;\nimport java.util.concurrent.atomic.AtomicInteger;\n/**\n * 线程工厂，它设置线程名称，有利于我们定位问题。\n */\npublic final class NamingThreadFactory implements ThreadFactory &#123;\n\n    private final AtomicInteger threadNum = new AtomicInteger();\n    private final ThreadFactory delegate;\n    private final String name;\n\n    /**\n     * 创建一个带名字的线程池生产工厂\n     */\n    public NamingThreadFactory(ThreadFactory delegate, String name) &#123;\n        this.delegate = delegate;\n        this.name = name; // TODO consider uniquifying this\n    &#125;\n\n    @Override \n    public Thread newThread(Runnable r) &#123;\n        Thread t = delegate.newThread(r);\n        t.setName(name + \" [#\" + threadNum.incrementAndGet() + \"]\");\n        return t;\n    &#125;\n\n&#125;\n\n\n\n线程池状态源码中runState和workerCount维护是放在一起的\nprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\nctl的高3位保存runState，低29位保存workerCount\nprivate static int runStateOf(int c)     &#123; return c &amp; ~CAPACITY; &#125; //计算当前运行状态\nprivate static int workerCountOf(int c)  &#123; return c &amp; CAPACITY; &#125;  //计算当前线程数量\nprivate static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125;   //通过状态和线程数生成ctl\n\n\n\n\n\n\n运行状态\n状态描述\n\n\n\nrunning\n能接受新提交的任务，并能处理阻塞队列中的任务。\n\n\nShutdown\n关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。\n\n\nStop\n不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。\n\n\nTidying\n所有任务都终止了，workerCount为0\n\n\nTerminated\n在terminated() 方法执行完成后进入该状态\n\n\n\n任务调度过程\n首先检测线程池运行状态，如果不是RUNNING，则直接拒绝，线程池要保证在RUNNING的状态下执行任务。\n如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任务。\n如果workerCount &gt;&#x3D; corePoolSize，且线程池内的阻塞队列未满，则将任务添加到该阻塞队列中。\n如果workerCount &gt;&#x3D; corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新提交的任务。\n如果workerCount &gt;&#x3D; maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。\n\n阻塞队列\n\n线程池核心问题：设置参数ThreadPoolExecutor主要有7个参数\n\ncorePoolSize：the number of threads to keep in the pool, even if they are idle, unless {@code allowCoreThreadTimeOut} is set\n（核心线程数大小：不管它们创建以后是不是空闲的。线程池需要保持 corePoolSize 数量的线程，除非设置了 allowCoreThreadTimeOut。）\n\nmaximumPoolSize：the maximum number of threads to allow in the pool。\n（最大线程数：线程池中最多允许创建 maximumPoolSize 个线程。）\n\nkeepAliveTime：when the number of threads is greater than the core, this is the maximum time that excess idle threads will wait for new tasks before terminating。\n（存活时间：如果经过 keepAliveTime 时间后，超过核心线程数的线程还没有接受到新的任务，那就回收。）\n\nunit：the time unit for the {@code keepAliveTime} argument\n（keepAliveTime 的时间单位。）\n\nworkQueue：the queue to use for holding tasks before they are executed.  This queue will hold only the {@code Runnable} tasks submitted by the {@code execute} method。\n（存放待执行任务的队列：当提交的任务数超过核心线程数大小后，再提交的任务就存放在这里。它仅仅用来存放被 execute 方法提交的 Runnable 任务。所以这里就不要翻译为工作队列了，好吗？不要自己给自己挖坑。）\n\nthreadFactory：the factory to use when the executor creates a new thread。\n（线程工程：用来创建线程工厂。比如这里面可以自定义线程名称，当进行虚拟机栈分析时，看着名字就知道这个线程是哪里来的，不会懵逼。）\n\nhandler ：the handler to use when execution is blocked because the thread bounds and queue capacities are reached。\n（拒绝策略：当队列里面放满了任务、最大线程数的线程都在工作时，这时继续提交的任务线程池就处理不了，应该执行怎么样的拒绝策略。）\n\n\n其中最重要的是3个参数：corePoolSize，maximumPoolSize，workQueue\ncorePoolSize有一个简单并且适用面比较广的公式：\n\nCPU 密集型任务(N+1)： 这种任务消耗的主要是 CPU 资源，可以将线程数设置为 N（CPU 核心数）+1，比 CPU 核心数多出来的一个线程是为了防止线程偶发的缺页中断，或者其它原因导致的任务暂停而带来的影响。一旦任务暂停，CPU 就会处于空闲状态，而在这种情况下多出来的一个线程就可以充分利用 CPU 的空闲时间。(《Java并发编程实战》中的解释)\n\nI&#x2F;O 密集型任务(2N)： 这种任务应用起来，系统会用大部分的时间来处理 I&#x2F;O 交互，而线程在处理 I&#x2F;O 的时间段内不会占用 CPU 来处理，这时就可以将 CPU 交出给其它线程使用。因此在 I&#x2F;O 密集型任务的应用中，我们可以多配置一些线程，具体的计算方法是 2N。\n\n\n获取处理器逻辑核心数量\nint N_CPUS = Runtime.getRuntime().availableProcessors();\n\n\n\n如何判断是 CPU 密集任务还是 IO 密集任务？\nCPU 密集型简单理解就是利用 CPU 计算能力的任务比如你在内存中对大量数据进行排序。\n但凡涉及到网络读取，文件读取这类都是 IO 密集型，这类任务的特点是 CPU 计算耗费时间相比于等待 IO 操作完成的时间来说很少，大部分时间都花在了等待 IO 操作完成上。\n美团在实践中提出了将线程池参数动态化的方式\n线程池预热线程池被创建后如果没有任务过来，里面是不会有线程的。如果需要预热的话可以调用下面的两个方法\n第一个是全启动\n第二个是仅启动一个\n/**\n * Starts all core threads, causing them to idly wait for work. This\n * overrides the default policy of starting core threads only when\n * new tasks are executed.\n *\n * @return the number of threads started\n */\npublic int prestartAllCoreThreads() &#123;\n    int n = 0;\n    while (addWorker(null, true))\n        ++n;\n    return n;\n&#125;\n\n\n/**\n * Starts a core thread, causing it to idly wait for work. This\n * overrides the default policy of starting core threads only when\n * new tasks are executed. This method will return &#123;@code false&#125;\n * if all core threads have already been started.\n *\n * @return &#123;@code true&#125; if a thread was started\n */\npublic boolean prestartCoreThread() &#123;\n    return workerCountOf(ctl.get()) &lt; corePoolSize &amp;&amp;\n        addWorker(null, true);\n&#125;\n\n\n\n核心线程数会被回收吗核心线程数默认不会被回收。\n线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。\ntry &#123;\n  while (task != null || (task = getTask()) != null) &#123;\n    //执行任务\n  &#125;\n&#125; finally &#123;\n  processWorkerExit(w, completedAbruptly);//获取不到任务时，主动回收自己\n&#125;\n\n\n\n\n如需回收核心线程数，需要调用下面的方法\n/**\n     * Sets the policy governing whether core threads may time out and\n     * terminate if no tasks arrive within the keep-alive time, being\n     * replaced if needed when new tasks arrive. When false, core\n     * threads are never terminated due to lack of incoming\n     * tasks. When true, the same keep-alive policy applying to\n     * non-core threads applies also to core threads. To avoid\n     * continual thread replacement, the keep-alive time must be\n     * greater than zero when setting &#123;@code true&#125;. This method\n     * should in general be called before the pool is actively used.\n     *\n     * @param value &#123;@code true&#125; if should time out, else &#123;@code false&#125;\n     * @throws IllegalArgumentException if value is &#123;@code true&#125;\n     *         and the current keep-alive time is not greater than zero\n     *\n     * @since 1.6\n     */\n    public void allowCoreThreadTimeOut(boolean value) &#123;\n        if (value &amp;&amp; keepAliveTime &lt;= 0)\n            throw new IllegalArgumentException(\"Core threads must have nonzero keep alive times\");\n        if (value != allowCoreThreadTimeOut) &#123;\n            allowCoreThreadTimeOut = value;\n            if (value)\n                interruptIdleWorkers();\n        &#125;\n    &#125;\n\n\n\n\n\n参考美团线程池实践\n","categories":["concurrent"],"tags":["concurrent"]},{"title":"并发编程 - 线程池 Thread Pool","url":"http://fuheihei.github.io/java-concurrency-programming/thread-pool/","content":"本文介绍了Java中的几种线程池，及Executors构造线程池的用法。\nJava 线程池 Thread Pool构建新线程的开销较大。如果程序中需要创建大量很短生命期的线程，应该使用线程池，而不是将每个任务映射到一个单独线程。\n线程池中包含很多准备运行的线程，每为线程池提供一个Runnable实例，就会有一个池中的线程调用run方法。当run方法退出时，这个线程不会死亡，而是留在池中准备为下一个请求 (Runnable实例) 提供服务。\n执行器 Executors执行器有许多静态工厂方法，用来构造线程池。静态工厂方法返回类型为 ExecutorService\n 表格 Executors工厂方法 \n\n\n\n\n方法\n描述\n\n\n\nnewCachedThreadPool\n必要时创建新线程；空闲线程会保留60 s\n\n\nnewFixedThreadPool\n池中包含固定数目的线程；空闲线程会一直保留\n\n\nnewWorkStealingPool\n一种适合“fork-join”任务的线程池，其中复杂的任务会分解为更简单的任务，空闲线程会“密取”较简单的任务\n\n\nnewSingleThreadExecutor\n只有一个线程的“池”，会顺序地执行所提交的任务\n\n\nnewScheduledThreadPool\n用于调度执行的固定线程池\n\n\nnewSingleThreadScheduledExecutor\n用于调度执行的单线程池\n\n\n缓存线程池 newCachedThreadPool构造一个线程池，会立即执行各个任务。如果有空闲线程可用，就使用现有空闲线程执行任务；如果没有可用的空闲线程，则创建一个新线程。\n固定线程池 newFixedThreadPool构造一个固定大小的线程池。如果提交的任务数多于空闲线程数，就把未得到服务的任务放到队列中。当其他任务完成以后再运行这些排队的任务。\n单线程池 newSingleThreadExecutor是一个退化了的大小为1的线程池：由一个线程顺序地执行所提交的任务（顺序执行）。\n参考上面的 FixedThreadPool\n使用线程池的小结如果线程生存时间很短，或者大量时间都在阻塞，业务是轻量负载的，可以使用缓存线程池。\n为了获得最优的运行速度，业务是高负载的，可以令并发线程数等于处理内核数(查看CPU内核数方法见下文)。在这种情况下，就应该使用固定线程池，即并发线程总数有一个上限。\n单线程池对于性能分析很有帮助。如临时使用一个单线程池替换其他线程池，就能测量不适用并发的情况下应用的运行速度会慢多少。\n实际使用的时候推荐自己创建ThreadPoolExecutor (避免OOM)\n\nExecutors 返回线程池对象的弊端如下：\n\nFixedThreadPool 和 SingleThreadExecutor： 允许请求的队列长度为 &gt; Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。\nCachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 &gt; Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。\n\n\n综合来讲，因为队列上限和创建线程上限，导致OOM发生。\n除了避免 OOM 的原因之外，不推荐使用 Executors 提供的两种快捷的线程池的原因还有：\n\n实际使用中需要根据自己机器的性能、业务场景来手动配置线程池的参数比如核心线程数、使用的任务队列、饱和策略等等。\n我们应该显示地给我们的线程池命名，这样有助于我们定位问题。\n\n如何查看CPU内核数量Linux: cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uni\nMac: 查看物理内核 sysctl hw.physicalcpu\n逻辑内核 sysctl hw.logicalcpu\n\nExecutorService分析上文中的几种线程池都属于ThreadPoolExecutor类，实现了ExecutorService的接口。\n图 ExecutorService 继承关系\n\n\n\n\n\nFuture&lt;T> submit(Callable&lt;T> task);\nFuture&lt;?> submit(Runnable task);\nFuture&lt;T> submit(Runnable task, T result);\nvoid shutdown();\nList&lt;Runnable> shutdownNow();\n\n\n\n调用submit时，会得到Future对象，可用来得到结果(get)或者取消任务(cancel)。\n第二个submit返回的Future对象可以来调用isDone, cancel, isCancelled。但是get方法在完成的时候只是简单返回null。\n第三个submit也生成一个Future，它的get方法在完成的时候返回指定的result对象。\nshutdown 用于关闭线程池，被关闭的线程池不再接受新任务，当所有任务完成时，线程池中的线程死亡。\nshutdownNow 会取消所有尚未开始的任务。\n\nfork-join框架有一些应用可能对处理器内核分别使用一个线程，以完成计算密集型任务，如图像或视频处理的应用。Java 7 中新引入了fork-join框架，专门用来支持这一类应用。\n假设有一个处理任务，它可以很自然地分解为子任务，如下所示\nif problemSize &lt; threshold\n\tsolve problem directly\nelse\n&#123;\n\tbreak problem into subproblems\n\trecursively solve each subproblem\n\tconbine the results\n&#125;\n\n\n\n为了完成这种递归计算，需要提供扩展RecursiveTask&lt;T&gt;的类或者提供扩展RecursiveAction&lt;T&gt;的类。再覆盖compute方法来生成并调用子任务。\n例如\npublic class Counter extends RecursiveTask&lt;Integer> &#123;\n\n    private static final int THRESHOLD = 10;\n    int to, from;\n    private DoublePredicate filter;\n    int[] values;\n\n    public Counter(int[] numbers, int from, int to, DoublePredicate filter) &#123;\n        this.values = numbers;\n        this.from = from;\n        this.to = to;\n        this.filter = filter;\n    &#125;\n\n    @Override\n    protected Integer compute() &#123;\n        if (to - from &lt; THRESHOLD) &#123;\n            int count = 0;\n            for (int i = from; i &lt; to; i++) &#123;\n                if (filter.test(values[i])) count++;\n            &#125;\n            return count;\n        &#125; else &#123;\n            int mid = (to + from) / 2;\n            Counter first = new Counter(values, from, mid, filter);\n            Counter second = new Counter(values, mid, to, filter);\n            invokeAll(first, second);\n            return first.join() + second.join();\n        &#125;\n    &#125;\n&#125;\n\n\n\n在后台，fork-join采用了一种有效的智能方法来平衡可用线程的工作负载，这种方法称为工作密取(work-stealing)。一个工作线程将子任务压入双端队列的队头(只有一个线程可以访问队头，故可以不加锁)，另一个工作线程空闲时，它会从双端队列的队尾“密取”一个任务。\n\n⚠️警告: fork-join池是针对非阻塞工作负载优化的。如果向一个fork-join池增加很多阻塞任务，会使其无法有效工作。\n\n推荐解析ThreadPoolExecutor\n参考如何设置线程池参数？美团给出了一个让面试官虎躯一震的回答  作者: why技术\n","categories":["concurrent"],"tags":["concurrent"]},{"title":"如何写博客","url":"http://fuheihei.github.io/tools/how-to-write-blog/","content":"我建立博客的初心是记录技术，并将自己在编程中学到的知识，写成规范的文档形式，尽力做到对自己对他人都是有帮助的。\n1. 文档工具文档文件格式还是markdown为主\n2. markdown写作规范写作规范详细参考github上的 Markdown 编写规范-中文\n3. 字体字体颜色，正常字体是默认的黑色，参考配色的颜色设计网站\n1 - FlatUI 配色\n2 - Ant Design 配色\n红色 #fe6673  重要的内容\n蓝色 #3498db 新名词首次出现\n黄色 #f1c40f warning警告相关的颜色\n绿色 #27ae60 论证过程，或者过程性质的代码\n如下所示，在md中嵌入html标签\n&lt;span style=\"color:...\"> &lt;/span> &lt;!--用标签包裹需要上色的文字-->\n\n\n\n4. 代码代码部分格式以markdown样式为主，分为大的代码块（带行号）和普通代码行。\nhello world //代码块\n\nhello world 普通代码行\n5. 总结每天进步一点点，保持笔记的清晰有条理。\n","categories":["tools"],"tags":["blog"]},{"title":"个人博客搭建","url":"http://fuheihei.github.io/tools/how-to-build-my-blog/","content":"搭建个人博客 hexo+kaze+gitalk。\n我们经常会看到github有人有&lt;username&gt;.github.io形式的个人博客网页，他们是怎么做到的呢？\n仔细观察，不少人的博客底部还会出现 “powered by hexo” 或者 “由hexo强力驱动” 的字样\n通过下文，你也可以搭建一个自己的github pages博客\n1.Github Pages没错，浏览器中url为&lt;username&gt;.github.io形式的博客是github提供的一种博客功能，这个功能叫做github pages。当用户在github上新建了&lt;username&gt;.github.io的public的仓库(&lt;username&gt;和自己的github用户名一致)，就可以为自己生成对应的github pages。并且其他访客可以通过这个url访问你的博客。\n2. hexo项目构建2.1用 hexo初始化项目第一步，安装hexo\n通过hexo-cli的方式，构建博客项目会更容易。\n环境：需要git，node环境(&gt;&#x3D;12.0.0, 推荐nvm安装node)\nnpm install hexo-cli -g\n\n\n\n详细安装配置可以看hexo官网文档 (简便安装上面一行指令就够了)\n第二步，接着hexo在本地构建项目\nhexo init &lt;project_url> #初始化项目\ncd &lt;project_url> #进入项目路径\n\n\n\n常用的hexo指令\nhexo g #即 hexo generate，生成静态文件\nhexo s #即 hexo server，本地运行服务器\nhexo d #即 hexo deploy，部署服务器，常用指令 hexo clean &amp;&amp; hexo d\n\n\n\n2.2 新建github pages 仓库新建一个github项目，项目名为&#96;&#96;{username}.github.io，项目是public的而非private的。\n修改本地hexo项目根目录下的 _config.yml文件，添加 deploy 相关的属性。\n需要指定发布项目的repo，这里因为我们用的是github pages，github pages通常是 &#123;username&#125;.github.io&#96;形式的public仓库。\n# Deployment\n## Docs: https://hexo.io/docs/one-command-deployment\ndeploy:\n  type: git\n  repo: git@github.com:fuheihei/fuheihei.github.io.git # 指定为你的github pages的git地址\n  branch: main #对应的git分支\n\n3.博客主题的选取hexo构建的博客项目可以选取很多开源的hexo主题，类似于qq空间的皮肤，我们通过修改根目录下_config.yml中的属性theme: 就能指定对应的皮肤。\n例如\n想要选择的主题是anatole\n将主题项目 git clone 到项目中的themes文件夹下，修改项目根目录下的_config.yml中的属性\ntheme: anatole  #将theme指定为anatole\n# Extensions\n## Plugins: https://hexo.io/plugins/\n## Themes: https://hexo.io/themes/\n\n需要注意的是，如果指定为anatole，那么项目必须得有theme&#x2F;anatole文件夹。\n其他丰富的hexo主题请查阅: https://hexo.io/themes/\n4.写文章4.1 新建文章hexo new [layout] &lt;title文章名>\n例如 hexo new post how-to-build-my-blog\n[layout]可以是 post、page 和 draft，其位置和source&#x2F;_post，source&#x2F;page，source&#x2F;_draft是相关联的。\n4.2 发布文章hexo g #即 hexo generate，生成静态文件\nhexo s #即 hexo server，本地运行服务器\nhexo d #即 hexo deploy，部署服务器，也可以用指令 hexo clean &amp;&amp; hexo d\nhexo d可以将本地的hexo 项目转换成github pages需要的项目发布在你的github repo中，在浏览器输入 &lt;username&gt;.github.io 就能看到和本地一样的hexo博客了。\n5.评论系统完善的博客还应该提供访问用户讨论的机会。\n\n\ngitalk的demo图\n\n评论系统有很多，出于免费和效率考虑，此处使用gitalk\ngitalk是github提供的评论系统，免费；同时gitalk的用户评论文章的内容可以在repo生成对应的issues，可以起到邮件通知的效果，保证及时回复用户。\n(1)申请OAuth Apps在github -&gt; settings -&gt; Developer Settings -&gt; OAuth Apps 中申请新的OAuth项目。\nAuthorization callback URL 和 Homepage URL 属性都写&lt;username&gt;.github.io博客的地址。\n并点击按钮，生成 clientSecret，下面会用到。\n(2)填写gitalk的属性修改项目中的_config.yml文件，我的在theme/hexo-theme-Kaze/_config.yml中。修改对应gitalk配置的部分。\ngitalk:\n  clientID: &lt;clientID>\n  clientSecret: &lt;clientSecret>\n  repo: fuheihei.github.io\n  owner: fuheihei\n  admin: fuheihei\n  id: location.href # dont modify\n  distractionFreeMode: false\n  language: navigator.language || navigator.userLanguage\n  labels: ['Gitalk']\n  perPage: 10\n\n6.发布博客本地测试查看无误后，使用命令hexo clean &amp;&amp; hexo deploy可以上传change提交到&#123;username&#125;.github.io项目中。\n提交结果如下图所示\n\n\n提交记录demo图\n\n可以看到hexo deploy指令会自动生成git的提交到repo上，通常是以时间作为commit的message。\n7. 总结经过上述的步骤，相信你也会有一个较好的博客了，接下来开始享受写作吧！\n","categories":["tools"],"tags":["blog"]}]